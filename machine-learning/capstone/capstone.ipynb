{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Engineer Nanodegree\n",
    "## Supervised Learning\n",
    "## Capstone Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Read the data\n",
    "data = pd.read_csv(\"features.csv\")\n",
    "print(\"Data read successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation: Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of users: 72376\n",
      "Number of features: 50\n",
      "Number of paying students: 5084\n",
      "Number of regular students: 67292\n",
      "Conversion rate: 7.02%\n"
     ]
    }
   ],
   "source": [
    "# Calculate number of users\n",
    "n_users = len(data.index)\n",
    "\n",
    "# Calculate number of features\n",
    "n_features = len(data.columns[:-1])\n",
    "\n",
    "# Calculate paying students\n",
    "n_paying = len(data[data.is_paying_student == 1])\n",
    "\n",
    "# Calculate regular students\n",
    "n_regular = len(data[data.is_paying_student == 0])\n",
    "\n",
    "# Calculate conversion rate\n",
    "conversion_rate = float(n_paying) / n_users * 100\n",
    "\n",
    "# Print the results\n",
    "print(\"Total number of users: {}\".format(n_users))\n",
    "print(\"Number of features: {}\".format(n_features))\n",
    "print(\"Number of paying students: {}\".format(n_paying))\n",
    "print(\"Number of regular students: {}\".format(n_regular))\n",
    "print(\"Conversion rate: {:.2f}%\".format(conversion_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data\n",
    "### Identify feature and target columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature columns:\n",
      "['count_visits', 'webinar_enrollments', 'free_course_enrollments', 'is_home', 'is_50back', 'is_signin', 'is_business', 'is_success', 'is_referrer_instagram', 'is_referrer_android', 'is_referrer_github', 'is_drive', 'is_jobs', 'is_referrer_computerworld', 'is_us', 'is_referrer_catracalivre', 'is_weekday', 'is_nanodegree_home', 'is_fcop_ud', 'is_hire_talent', 'is_catalog_nanodegrees', 'is_mobile', 'is_ai', 'is_legal', 'is_checkout', 'is_contact', 'is_referrer_live', 'is_referrer_linkedin', 'is_referrer_google', 'is_referrer_anhanguera', 'is_referrer_infomoney', 'is_referrer_cbsi', 'is_catalog_all', 'is_robotics', 'is_event', 'is_referrer_bing', 'is_payment', 'is_tech_requirements', 'is_android', 'is_ndop', 'is_referrer_facebook', 'is_fcop_st', 'is_referrer_tecmundo', 'is_fcop_cs']\n",
      "\n",
      "Target column: is_paying_student\n",
      "\n",
      "Feature values:\n",
      "                              0\n",
      "count_visits               40.0\n",
      "webinar_enrollments         0.0\n",
      "free_course_enrollments     4.0\n",
      "is_home                    14.0\n",
      "is_50back                   0.0\n",
      "is_signin                   5.0\n",
      "is_business                 0.0\n",
      "is_success                  0.0\n",
      "is_referrer_instagram       0.0\n",
      "is_referrer_android         0.0\n",
      "is_referrer_github          0.0\n",
      "is_drive                    0.0\n",
      "is_jobs                     0.0\n",
      "is_referrer_computerworld   0.0\n",
      "is_us                       0.0\n",
      "is_referrer_catracalivre    0.0\n",
      "is_weekday                 34.0\n",
      "is_nanodegree_home          2.0\n",
      "is_fcop_ud                  2.0\n",
      "is_hire_talent              0.0\n",
      "is_catalog_nanodegrees      5.0\n",
      "is_mobile                   0.0\n",
      "is_ai                       0.0\n",
      "is_legal                    0.0\n",
      "is_checkout                 0.0\n",
      "is_contact                  0.0\n",
      "is_referrer_live            0.0\n",
      "is_referrer_linkedin        0.0\n",
      "is_referrer_google          3.0\n",
      "is_referrer_anhanguera      0.0\n",
      "is_referrer_infomoney       0.0\n",
      "is_referrer_cbsi            0.0\n",
      "is_catalog_all              9.0\n",
      "is_robotics                 0.0\n",
      "is_event                    0.0\n",
      "is_referrer_bing            0.0\n",
      "is_payment                  0.0\n",
      "is_tech_requirements        0.0\n",
      "is_android                  0.0\n",
      "is_ndop                     0.0\n",
      "is_referrer_facebook        0.0\n",
      "is_fcop_st                  0.0\n",
      "is_referrer_tecmundo        0.0\n",
      "is_fcop_cs                  3.0\n"
     ]
    }
   ],
   "source": [
    "data = data.fillna(0)\n",
    "\n",
    "# Extract feature columns\n",
    "feature_cols = list(data.columns[6:-1])\n",
    "\n",
    "# Extract target column 'passed'\n",
    "target_col = data.columns[-1] \n",
    "\n",
    "# Show the list of columns\n",
    "print(\"Feature columns:\\n{}\".format(feature_cols))\n",
    "print(\"\\nTarget column: {}\".format(target_col))\n",
    "\n",
    "# Separate the data into feature data and target data (X_all and y_all, respectively)\n",
    "X_all = data[feature_cols]\n",
    "y_all = data[target_col]\n",
    "\n",
    "# Show the feature information by printing the first five rows\n",
    "print(\"\\nFeature values:\")\n",
    "print(X_all.head(1).transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation: Training and Testing Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 54282 samples.\n",
      "Testing set has 18094 samples.\n"
     ]
    }
   ],
   "source": [
    "# Import any additional functionality you may need here\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set the number of training points\n",
    "num_train = int(0.75 * X_all.shape[0])\n",
    "\n",
    "# Set the number of testing points\n",
    "num_test = X_all.shape[0] - num_train\n",
    "\n",
    "# Shuffle and split the dataset into the number of training and testing points above\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=num_test, random_state=42)\n",
    "\n",
    "\n",
    "# Show the results of the split\n",
    "print(\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "print(\"Testing set has {} samples.\".format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set conversion rate: 0.070\n",
      "Testing set conversion rate: 0.072\n"
     ]
    }
   ],
   "source": [
    "train_conversion_rate = y_train.sum() / y_train.shape[0]\n",
    "test_conversion_rate = y_test.sum() / y_test.shape[0]\n",
    "print(\"Training set conversion rate: {:.3f}\".format(train_conversion_rate))\n",
    "print(\"Testing set conversion rate: {:.3f}\".format(test_conversion_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Evaluating Models\n",
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_classifier(clf, X_train, y_train):\n",
    "    ''' Fits a classifier to the training data. '''\n",
    "    \n",
    "    # Start the clock, train the classifier, then stop the clock\n",
    "    start = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time()\n",
    "    \n",
    "    # Print the results\n",
    "    print(\"Trained model in {:.4f} seconds\".format(end - start))\n",
    "\n",
    "    \n",
    "def predict_labels(clf, features, target):\n",
    "    ''' Makes predictions using a fit classifier based on F1 score. '''\n",
    "    \n",
    "    # Start the clock, make predictions, then stop the clock\n",
    "    start = time()\n",
    "    y_pred = clf.predict(features)\n",
    "    end = time()\n",
    "    \n",
    "    # Print and return results\n",
    "    print(\"Made predictions in {:.4f} seconds.\".format(end - start))\n",
    "    return f1_score(target.values, y_pred, pos_label=1)\n",
    "\n",
    "\n",
    "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
    "    ''' Train and predict using a classifer based on F1 score. '''\n",
    "    \n",
    "    # Indicate the classifier and the training set size\n",
    "    print(\"\\nTraining a {} using a training set size of {}. . .\".format(clf.__class__.__name__, len(X_train)))\n",
    "    \n",
    "    # Train the classifier\n",
    "    train_classifier(clf, X_train, y_train)\n",
    "    \n",
    "    # Print the results of prediction for both training and testing\n",
    "    print(\"F1 score for training set: {:.4f}.\".format(predict_labels(clf, X_train, y_train)))\n",
    "    print(\"F1 score for test set: {:.4f}.\".format(predict_labels(clf, X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation: Model Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GaussianNB: \n",
      "\n",
      "Training a GaussianNB using a training set size of 18094. . .\n",
      "Trained model in 0.0250 seconds\n",
      "Made predictions in 0.0215 seconds.\n",
      "F1 score for training set: 0.1343.\n",
      "Made predictions in 0.0172 seconds.\n",
      "F1 score for test set: 0.1336.\n",
      "\n",
      "Training a GaussianNB using a training set size of 36188. . .\n",
      "Trained model in 0.0423 seconds\n",
      "Made predictions in 0.0414 seconds.\n",
      "F1 score for training set: 0.1103.\n",
      "Made predictions in 0.0168 seconds.\n",
      "F1 score for test set: 0.1132.\n",
      "\n",
      "Training a GaussianNB using a training set size of 54282. . .\n",
      "Trained model in 0.0768 seconds\n",
      "Made predictions in 0.0613 seconds.\n",
      "F1 score for training set: 0.1120.\n",
      "Made predictions in 0.0227 seconds.\n",
      "F1 score for test set: 0.1163.\n",
      "\n",
      "SGDClassifier: \n",
      "\n",
      "Training a SGDClassifier using a training set size of 18094. . .\n",
      "Trained model in 0.0276 seconds\n",
      "Made predictions in 0.0053 seconds.\n",
      "F1 score for training set: 0.1216.\n",
      "Made predictions in 0.0030 seconds.\n",
      "F1 score for test set: 0.1096.\n",
      "\n",
      "Training a SGDClassifier using a training set size of 36188. . .\n",
      "Trained model in 0.0415 seconds\n",
      "Made predictions in 0.0077 seconds.\n",
      "F1 score for training set: 0.1555.\n",
      "Made predictions in 0.0030 seconds.\n",
      "F1 score for test set: 0.1621.\n",
      "\n",
      "Training a SGDClassifier using a training set size of 54282. . .\n",
      "Trained model in 0.0673 seconds\n",
      "Made predictions in 0.0088 seconds.\n",
      "F1 score for training set: 0.0400.\n",
      "Made predictions in 0.0032 seconds.\n",
      "F1 score for test set: 0.0336.\n",
      "\n",
      "KNeighborsClassifier: \n",
      "\n",
      "Training a KNeighborsClassifier using a training set size of 18094. . .\n",
      "Trained model in 0.1431 seconds\n",
      "Made predictions in 4.1851 seconds.\n",
      "F1 score for training set: 0.2471.\n",
      "Made predictions in 4.2948 seconds.\n",
      "F1 score for test set: 0.1550.\n",
      "\n",
      "Training a KNeighborsClassifier using a training set size of 36188. . .\n",
      "Trained model in 0.8804 seconds\n",
      "Made predictions in 14.5662 seconds.\n",
      "F1 score for training set: 0.2679.\n",
      "Made predictions in 8.5632 seconds.\n",
      "F1 score for test set: 0.1777.\n",
      "\n",
      "Training a KNeighborsClassifier using a training set size of 54282. . .\n",
      "Trained model in 1.9522 seconds\n",
      "Made predictions in 33.0726 seconds.\n",
      "F1 score for training set: 0.2780.\n",
      "Made predictions in 10.7874 seconds.\n",
      "F1 score for test set: 0.1770.\n",
      "\n",
      "XGBClassifier: \n",
      "\n",
      "Training a XGBClassifier using a training set size of 18094. . .\n",
      "Trained model in 2.2294 seconds\n",
      "Made predictions in 0.0561 seconds.\n",
      "F1 score for training set: 0.2580.\n",
      "Made predictions in 0.0496 seconds.\n",
      "F1 score for test set: 0.1977.\n",
      "\n",
      "Training a XGBClassifier using a training set size of 36188. . .\n",
      "Trained model in 4.3479 seconds\n",
      "Made predictions in 0.1149 seconds.\n",
      "F1 score for training set: 0.2572.\n",
      "Made predictions in 0.0514 seconds.\n",
      "F1 score for test set: 0.2074.\n",
      "\n",
      "Training a XGBClassifier using a training set size of 54282. . .\n",
      "Trained model in 7.0589 seconds\n",
      "Made predictions in 0.2224 seconds.\n",
      "F1 score for training set: 0.2468.\n",
      "Made predictions in 0.0665 seconds.\n",
      "F1 score for test set: 0.2059.\n"
     ]
    }
   ],
   "source": [
    "# Import the three supervised learning models from sklearn\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "# Initialize the three models\n",
    "clf_A = GaussianNB()\n",
    "clf_B = SGDClassifier() #svm.SVC(random_state=42)\n",
    "clf_C = KNeighborsClassifier()\n",
    "clf_D = xgb.XGBClassifier()\n",
    "\n",
    "# Execute the 'train_predict' function for each classifier and each training set size\n",
    "for clf in [clf_A, clf_B, clf_C, clf_D]:\n",
    "    print(\"\\n{}: \".format(clf.__class__.__name__))\n",
    "    for n in [int(X_train.shape[0] / 3), int( 2 / 3 * X_train.shape[0]), X_train.shape[0]]:\n",
    "        train_predict(clf, X_train[:n], y_train[:n], X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize the classifier\n",
    "clf = clf_D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation: Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import 'GridSearchCV' and 'make_scorer'\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Create the parameters list you wish to tune\n",
    "#parameters = [{'kernel': ['rbf'], 'gamma': [1e-2, 1e-3, 2e-3, 1e-4], 'C': [1, 5, 10, 50, 100, 150, 200, 250]}]\n",
    "parameters = [{'learning_rate': [0.1, 0.3, 0.5, 0.7, 0.9], \n",
    "              'max_depth': [3, 4, 5, 6, 7, 8, 9, 10],\n",
    "              'min_child_weight': [1, 2, 3, 4, 5],\n",
    "              'max_delta_step': [0, 1, 2, 3, 4, 5],\n",
    "              'subsample': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    "              'colsample_bytree': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    "              'colsample_bylevel': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]}]\n",
    "\n",
    "# Create Cross-Validation Sets\n",
    "cv_sets = ShuffleSplit(X_train.shape[0], test_size=0.4, random_state=42)\n",
    "\n",
    "# Make an f1 scoring function using 'make_scorer'\n",
    "f1_scorer = make_scorer(f1_score, pos_label=1)\n",
    "\n",
    "# Perform grid search on the classifier using the f1_scorer as the scoring method\n",
    "grid_obj = GridSearchCV(clf, parameters, f1_scorer, cv=cv_sets)\n",
    "\n",
    "# Fit the grid search object to the training data and find the optimal parameters\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Get the estimator\n",
    "clf = grid_obj.best_estimator_\n",
    "\n",
    "# Report the final F1 score for training and testing after parameter tuning\n",
    "print(\"\\nTuned model has a training F1 score of {:.4f}.\".format(predict_labels(clf, X_train, y_train)))\n",
    "print(\"Tuned model has a testing F1 score of {:.4f}.\".format(predict_labels(clf, X_test, y_test)))\n",
    "\n",
    "print(grid_obj.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
