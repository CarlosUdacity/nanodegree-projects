{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Começando com o TensorFlow\n",
    "O objetivo desse notebook é experimentar o **TensorFlow**, biblioteca de deep learning do **Google**.\n",
    "Pré-requisitos:\n",
    "- Saber programar em Python\n",
    "- Conhecer um pouco de machine learning\n",
    "- Conhecer um pouco de álgebra linear e cálculo\n",
    "\n",
    "Para mais informações, acesse [a documentação do TensorFlow](https://www.tensorflow.org/get_started/get_started)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensores\n",
    "A unidade central do TensorFlow é o **tensor**. Um tensor nada mais é do que um conjunto de valores organizados num array de **N** dimensões. Exemplos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from graphviz import Digraph\n",
    "\n",
    "t1 = np.array(3)                          # tensor de rank 0\n",
    "t2 = np.array([1, 2, 3])                  # tensor de rank 1\n",
    "t3 = np.array([[1, 2, 3], [4, 5, 6]])     # tensor de rank 2\n",
    "t4 = np.array([[[1, 2, 3]], [[5, 6, 7]]]) # tensor de rank 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grafos computacionais\n",
    "Um programa no TensorFlow é construído em 2 etapas:\n",
    "1. **Construindo** o grafo computacional;\n",
    "2. **Rodando** o grafo computacional.\n",
    "\n",
    "Um **grafo computacional** é uma série de operações no TensorFlow organizadas num grafo de nós ou vértices. <br/>\n",
    "Cada **nó ou vértice** recebe de zero a N tensores como **input**, e um tensor como **output**. <br/>\n",
    "Um vértice constante não recebe nenhum input, e produz como output um valor constante guardado internamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_8:0\", shape=(), dtype=float32) Tensor(\"Const_9:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "vertice1 = tf.constant(2., dtype=tf.float32)\n",
    "vertice2 = tf.constant(3.)    # implicitamente tf.float32\n",
    "print(vertice1, vertice2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao imprimir os vértices, não vemos ``2.0`` e ``3.0``. Vemos os vértices. <br/>\n",
    "Para vermos os valores, precisamos **rodar o gráfo computacional** dentro de uma **sessão**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.0, 3.0]\n"
     ]
    }
   ],
   "source": [
    "sessao = tf.Session()\n",
    "print(sessao.run([vertice1, vertice2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos calcular operações mais complexas combinando **vértices** com operações. Operações **também** são **vértices**. <br/>\n",
    "Por exemplo, adicionando os dois vértices constantes produzimos um novo grafo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vertice3:  Tensor(\"Add:0\", shape=(), dtype=float32)\n",
      "sessan.run(vertice3):  5.0\n"
     ]
    }
   ],
   "source": [
    "vertice3 = tf.add(vertice1, vertice2)\n",
    "print('vertice3: ', vertice3)\n",
    "print('sessan.run(vertice3): ', sessao.run(vertice3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vértices constantes não são muito interessantes. Um grafo pode ser parametrizado para aceitar inputs externos, chamados de **placeholders**. <br/>\n",
    "Um **placeholder** é uma promessa de prover um valor mais tarde:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "soma = a + b   # a mesma coisa que tf.add(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"156pt\" height=\"98pt\"\n",
       " viewBox=\"0.00 0.00 155.55 98.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 94)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-94 151.548,-94 151.548,4 -4,4\"/>\n",
       "<!-- a -->\n",
       "<g id=\"node1\" class=\"node\"><title>a</title>\n",
       "<ellipse fill=\"lightblue\" stroke=\"lightblue\" cx=\"27\" cy=\"-72\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-67.8\" font-family=\"Times,serif\" font-size=\"14.00\">a</text>\n",
       "</g>\n",
       "<!-- soma -->\n",
       "<g id=\"node2\" class=\"node\"><title>soma</title>\n",
       "<ellipse fill=\"lightblue\" stroke=\"lightblue\" cx=\"118.774\" cy=\"-45\" rx=\"28.5497\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"118.774\" y=\"-40.8\" font-family=\"Times,serif\" font-size=\"14.00\">soma</text>\n",
       "</g>\n",
       "<!-- a&#45;&gt;soma -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>a&#45;&gt;soma</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M52.0578,-64.7645C61.4066,-61.9528 72.3043,-58.6753 82.5063,-55.6069\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"83.8251,-58.8652 92.3933,-52.6334 81.809,-52.1618 83.8251,-58.8652\"/>\n",
       "</g>\n",
       "<!-- b -->\n",
       "<g id=\"node3\" class=\"node\"><title>b</title>\n",
       "<ellipse fill=\"lightblue\" stroke=\"lightblue\" cx=\"27\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\">b</text>\n",
       "</g>\n",
       "<!-- b&#45;&gt;soma -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>b&#45;&gt;soma</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M52.0578,-25.2355C61.4066,-28.0472 72.3043,-31.3247 82.5063,-34.3931\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"81.809,-37.8382 92.3933,-37.3666 83.8251,-31.1348 81.809,-37.8382\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x118013d68>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc = Digraph()\n",
    "gc.attr(rankdir='LR'); gc.node_attr.update(color='lightblue', style='filled')\n",
    "gc.edge('a', 'soma')\n",
    "gc.edge('b', 'soma')\n",
    "gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As linhas acima são **como uma função**, que **recebe dois tensores como input**, e **produz um tensor como output** sendo a soma dos inputs. <br/>\n",
    "Para passarmos os inputs, ao rodar o grafo, usamos o parâmetro **feed_dict**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.5\n",
      "[ 4.  2.]\n"
     ]
    }
   ],
   "source": [
    "print(sessao.run(soma, feed_dict={a: 4, b: 2.5}))\n",
    "print(sessao.run(soma, feed_dict={a: [3, 6], b: [1, -4]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos aumentar a complexidade do grafo adicionando operações:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 36.   4.  44.]\n"
     ]
    }
   ],
   "source": [
    "soma_e_mult = soma * 4.\n",
    "print(sessao.run(soma_e_mult, {a: [3, -1, 5], b: [6, 2, 6]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em machine learning, para que os modelos sejam treináveis, precisamos modificar os grafos para que obtenhamos outputs diferentes a partir de um mesmo input (que minimize uma função de erro). <br/>\n",
    "Para isso, usamos **variáveis**: elas nos permitem adicionar parâmetros treináveis nos grafos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32)\n",
    "W = tf.Variable([.5], dtype=tf.float32)\n",
    "b = tf.Variable([-.5], dtype=tf.float32)\n",
    "modelo_linear = W * x + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diferente das constantes, que são inicializadas na sua criação e nunca mudam, as variáveis precisam ser **inicializadas**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sessao.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como **x** é um **placeholder**, podemos avaliar o modelo linear que criamos para vários valores de **x ao mesmo tempo**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.   0.5  1.   1.5]\n"
     ]
    }
   ],
   "source": [
    "print(sessao.run(modelo_linear, {x: [1, 2, 3, 4]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criamos o modelo, mas não sabemos o quão bom ele é. Para avaliarmos o modelo, precisamos de um **placeholder y** para entrar com os valores desejados, e de uma **função de erro (loss function)** que será minimizada.\n",
    "\n",
    "A função de erro serve para nos dizer o quão longe o nosso modelo está dos dados fornecidos, ou seja, da realidade. A forma mais utilizada em regressões lineares é a função que calcula a raiz quadrada da soma entre os deltas do modelo e dos dados fornecidos. **``modelo_linear - y``** criará um vetor onde cada elemento será o delta. **``tf.square``** calculará a raiz quadrada. **``tf.reduce_sum``** somará todos os deltas num valor escalar único, que indicará o erro a ser minimizado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.5\n"
     ]
    }
   ],
   "source": [
    "y = tf.placeholder(tf.float32)\n",
    "raiz_deltas = tf.square(modelo_linear - y)\n",
    "erro = tf.reduce_sum(raiz_deltas)\n",
    "print(sessao.run(erro, {x: [1, 2, 3, 4], y: [0, -1, -2, -3]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinando o modelo e minimizando o erro\n",
    "Precisamos encontrar **W** e **b** que minimizam o erro, para que nosso modelo represente bem a realidade. Para isso, usaremos **otimizadores** do TensorFlow, que mudam cada variável passo-a-passo em busca de **minimizar a função de erro, ou loss function**. <br/>\n",
    "O otimizador mais simples é o **método do gradiente, ou gradient descent**, que modifica cada variável de acordo com a magnitude da derivada do erro com respeito àquela variável:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-4.99998665], dtype=float32), array([ 4.99995995], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "otimizador = tf.train.GradientDescentOptimizer(0.01)\n",
    "treino = otimizador.minimize(erro)\n",
    "\n",
    "sessao.run(init)\n",
    "for i in range(1000):\n",
    "    sessao.run(treino, {x: [1, 2, 3, 4], y: [0, -5, -10, -15]})\n",
    "    \n",
    "print(sessao.run([W, b]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O programa completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: -4.999988  |  b: 4.999964  |  erro: 0.000000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Inicializando os placeholders do modelo\n",
    "x = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)\n",
    "\n",
    "# Inicializando as variáveis que queremos determinar\n",
    "W = tf.Variable([.1], dtype=tf.float32)\n",
    "b = tf.Variable([.1], dtype=tf.float32)\n",
    "\n",
    "# Inicializando o modelo linear\n",
    "modelo_linear = W * x + b\n",
    "\n",
    "# Inicializando o otimizador e o erro\n",
    "raiz_deltas = tf.square(modelo_linear - y)\n",
    "erro = tf.reduce_sum(raiz_deltas)\n",
    "otimizador = tf.train.GradientDescentOptimizer(0.01)\n",
    "treino = otimizador.minimize(erro)\n",
    "\n",
    "# Entrando com os dados para treinamento do modelo\n",
    "x_treino = [1, 2, 3, 4]\n",
    "y_treino = [0, -5, -10, -15]\n",
    "iteracoes = 1000\n",
    "\n",
    "# Inicializando o TensorFlow\n",
    "init = tf.global_variables_initializer()\n",
    "sessao = tf.Session()\n",
    "sessao.run(init)\n",
    "\n",
    "# Treinando o modelo\n",
    "for i in range(iteracoes):\n",
    "    sessao.run(treino, {x: x_treino, y: y_treino})\n",
    "\n",
    "# Imprimindo os resultados\n",
    "W_final, b_final, erro_final = sessao.run([W, b, erro], {x: x_treino, y: y_treino})\n",
    "\n",
    "print('W: %f  |  b: %f  |  erro: %f' % (W_final, b_final, erro_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
