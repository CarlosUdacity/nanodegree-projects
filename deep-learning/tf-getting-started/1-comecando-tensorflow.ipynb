{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Começando com o TensorFlow\n",
    "O objetivo desse notebook é experimentar o **TensorFlow**, biblioteca de deep learning do **Google**.\n",
    "Pré-requisitos:\n",
    "- Saber programar em Python\n",
    "- Conhecer um pouco de machine learning\n",
    "- Conhecer um pouco de álgebra linear e cálculo\n",
    "\n",
    "Para mais informações, acesse [a documentação do TensorFlow](https://www.tensorflow.org/get_started/get_started)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensores\n",
    "A unidade central do TensorFlow é o **tensor**. Um tensor nada mais é do que um conjunto de valores organizados num array de **N** dimensões. Exemplos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from graphviz import Digraph\n",
    "\n",
    "t1 = np.array(3)                          # tensor de rank 0\n",
    "t2 = np.array([1, 2, 3])                  # tensor de rank 1\n",
    "t3 = np.array([[1, 2, 3], [4, 5, 6]])     # tensor de rank 2\n",
    "t4 = np.array([[[1, 2, 3]], [[5, 6, 7]]]) # tensor de rank 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grafos computacionais\n",
    "Um programa no TensorFlow é construído em 2 etapas:\n",
    "1. **Construindo** o grafo computacional;\n",
    "2. **Rodando** o grafo computacional.\n",
    "\n",
    "Um **grafo computacional** é uma série de operações no TensorFlow organizadas num grafo de nós ou vértices. <br/>\n",
    "Cada **nó ou vértice** recebe de zero a N tensores como **input**, e um tensor como **output**. <br/>\n",
    "Um vértice constante não recebe nenhum input, e produz como output um valor constante guardado internamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_8:0\", shape=(), dtype=float32) Tensor(\"Const_9:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "vertice1 = tf.constant(2., dtype=tf.float32)\n",
    "vertice2 = tf.constant(3.)    # implicitamente tf.float32\n",
    "print(vertice1, vertice2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao imprimir os vértices, não vemos ``2.0`` e ``3.0``. Vemos os vértices. <br/>\n",
    "Para vermos os valores, precisamos **rodar o gráfo computacional** dentro de uma **sessão**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.0, 3.0]\n"
     ]
    }
   ],
   "source": [
    "sessao = tf.Session()\n",
    "print(sessao.run([vertice1, vertice2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos calcular operações mais complexas combinando **vértices** com operações. Operações **também** são **vértices**. <br/>\n",
    "Por exemplo, adicionando os dois vértices constantes produzimos um novo grafo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vertice3:  Tensor(\"Add:0\", shape=(), dtype=float32)\n",
      "sessan.run(vertice3):  5.0\n"
     ]
    }
   ],
   "source": [
    "vertice3 = tf.add(vertice1, vertice2)\n",
    "print('vertice3: ', vertice3)\n",
    "print('sessan.run(vertice3): ', sessao.run(vertice3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vértices constantes não são muito interessantes. Um grafo pode ser parametrizado para aceitar inputs externos, chamados de **placeholders**. <br/>\n",
    "Um **placeholder** é uma promessa de prover um valor mais tarde:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "soma = a + b   # a mesma coisa que tf.add(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"156pt\" height=\"98pt\"\n",
       " viewBox=\"0.00 0.00 155.55 98.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 94)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-94 151.548,-94 151.548,4 -4,4\"/>\n",
       "<!-- a -->\n",
       "<g id=\"node1\" class=\"node\"><title>a</title>\n",
       "<ellipse fill=\"lightblue\" stroke=\"lightblue\" cx=\"27\" cy=\"-72\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-67.8\" font-family=\"Times,serif\" font-size=\"14.00\">a</text>\n",
       "</g>\n",
       "<!-- soma -->\n",
       "<g id=\"node2\" class=\"node\"><title>soma</title>\n",
       "<ellipse fill=\"lightblue\" stroke=\"lightblue\" cx=\"118.774\" cy=\"-45\" rx=\"28.5497\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"118.774\" y=\"-40.8\" font-family=\"Times,serif\" font-size=\"14.00\">soma</text>\n",
       "</g>\n",
       "<!-- a&#45;&gt;soma -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>a&#45;&gt;soma</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M52.0578,-64.7645C61.4066,-61.9528 72.3043,-58.6753 82.5063,-55.6069\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"83.8251,-58.8652 92.3933,-52.6334 81.809,-52.1618 83.8251,-58.8652\"/>\n",
       "</g>\n",
       "<!-- b -->\n",
       "<g id=\"node3\" class=\"node\"><title>b</title>\n",
       "<ellipse fill=\"lightblue\" stroke=\"lightblue\" cx=\"27\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\">b</text>\n",
       "</g>\n",
       "<!-- b&#45;&gt;soma -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>b&#45;&gt;soma</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M52.0578,-25.2355C61.4066,-28.0472 72.3043,-31.3247 82.5063,-34.3931\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"81.809,-37.8382 92.3933,-37.3666 83.8251,-31.1348 81.809,-37.8382\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x118013d68>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc = Digraph()\n",
    "gc.attr(rankdir='LR'); gc.node_attr.update(color='lightblue', style='filled')\n",
    "gc.edge('a', 'soma')\n",
    "gc.edge('b', 'soma')\n",
    "gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As linhas acima são **como uma função**, que **recebe dois tensores como input**, e **produz um tensor como output** sendo a soma dos inputs. <br/>\n",
    "Para passarmos os inputs, ao rodar o grafo, usamos o parâmetro **feed_dict**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.5\n",
      "[ 4.  2.]\n"
     ]
    }
   ],
   "source": [
    "print(sessao.run(soma, feed_dict={a: 4, b: 2.5}))\n",
    "print(sessao.run(soma, feed_dict={a: [3, 6], b: [1, -4]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos aumentar a complexidade do grafo adicionando operações:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 36.   4.  44.]\n"
     ]
    }
   ],
   "source": [
    "soma_e_mult = soma * 4.\n",
    "print(sessao.run(soma_e_mult, {a: [3, -1, 5], b: [6, 2, 6]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em machine learning, para que os modelos sejam treináveis, precisamos modificar os grafos para que obtenhamos outputs diferentes a partir de um mesmo input (que minimize uma função de erro). <br/>\n",
    "Para isso, usamos **variáveis**: elas nos permitem adicionar parâmetros treináveis nos grafos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32)\n",
    "W = tf.Variable([.5], dtype=tf.float32)\n",
    "b = tf.Variable([-.5], dtype=tf.float32)\n",
    "modelo_linear = W * x + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diferente das constantes, que são inicializadas na sua criação e nunca mudam, as variáveis precisam ser **inicializadas**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sessao.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como **x** é um **placeholder**, podemos avaliar o modelo linear que criamos para vários valores de **x ao mesmo tempo**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.   0.5  1.   1.5]\n"
     ]
    }
   ],
   "source": [
    "print(sessao.run(modelo_linear, {x: [1, 2, 3, 4]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criamos o modelo, mas não sabemos o quão bom ele é. Para avaliarmos o modelo, precisamos de um **placeholder y** para entrar com os valores desejados, e de uma **função de erro (loss function)** que será minimizada.\n",
    "\n",
    "A função de erro serve para nos dizer o quão longe o nosso modelo está dos dados fornecidos, ou seja, da realidade. A forma mais utilizada em regressões lineares é a função que calcula a raiz quadrada da soma entre os deltas do modelo e dos dados fornecidos. **``modelo_linear - y``** criará um vetor onde cada elemento será o delta. **``tf.square``** calculará a raiz quadrada. **``tf.reduce_sum``** somará todos os deltas num valor escalar único, que indicará o erro a ser minimizado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.5\n"
     ]
    }
   ],
   "source": [
    "y = tf.placeholder(tf.float32)\n",
    "raiz_deltas = tf.square(modelo_linear - y)\n",
    "erro = tf.reduce_sum(raiz_deltas)\n",
    "print(sessao.run(erro, {x: [1, 2, 3, 4], y: [0, -1, -2, -3]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinando o modelo e minimizando o erro\n",
    "Precisamos encontrar **W** e **b** que minimizam o erro, para que nosso modelo represente bem a realidade. Para isso, usaremos **otimizadores** do TensorFlow, que mudam cada variável passo-a-passo em busca de **minimizar a função de erro, ou loss function**. <br/>\n",
    "O otimizador mais simples é o **método do gradiente, ou gradient descent**, que modifica cada variável de acordo com a magnitude da derivada do erro com respeito àquela variável:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-4.99998665], dtype=float32), array([ 4.99995995], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "otimizador = tf.train.GradientDescentOptimizer(0.01)\n",
    "treino = otimizador.minimize(erro)\n",
    "\n",
    "sessao.run(init)\n",
    "for i in range(1000):\n",
    "    sessao.run(treino, {x: [1, 2, 3, 4], y: [0, -5, -10, -15]})\n",
    "    \n",
    "print(sessao.run([W, b]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O programa completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: -4.999988  |  b: 4.999964  |  erro: 0.000000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Inicializando os placeholders do modelo\n",
    "x = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)\n",
    "\n",
    "# Inicializando as variáveis que queremos determinar\n",
    "W = tf.Variable([.1], dtype=tf.float32)\n",
    "b = tf.Variable([.1], dtype=tf.float32)\n",
    "\n",
    "# Inicializando o modelo linear\n",
    "modelo_linear = W * x + b\n",
    "\n",
    "# Inicializando o otimizador e o erro\n",
    "raiz_deltas = tf.square(modelo_linear - y)\n",
    "erro = tf.reduce_sum(raiz_deltas)\n",
    "otimizador = tf.train.GradientDescentOptimizer(0.01)\n",
    "treino = otimizador.minimize(erro)\n",
    "\n",
    "# Entrando com os dados para treinamento do modelo\n",
    "x_treino = [1, 2, 3, 4]\n",
    "y_treino = [0, -5, -10, -15]\n",
    "iteracoes = 1000\n",
    "\n",
    "# Inicializando o TensorFlow\n",
    "init = tf.global_variables_initializer()\n",
    "sessao = tf.Session()\n",
    "sessao.run(init)\n",
    "\n",
    "# Treinando o modelo\n",
    "for i in range(iteracoes):\n",
    "    sessao.run(treino, {x: x_treino, y: y_treino})\n",
    "\n",
    "# Imprimindo os resultados\n",
    "W_final, b_final, erro_final = sessao.run([W, b, erro], {x: x_treino, y: y_treino})\n",
    "\n",
    "print('W: %f  |  b: %f  |  erro: %f' % (W_final, b_final, erro_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.estimator\n",
    "Essa biblioteca do TensorFlow simplifica o código que escrevemos para o machine learning. Ela ajuda a:\n",
    "- rodar loops de treinamento\n",
    "- rodar loops de avaliação\n",
    "- manipular datasets\n",
    "\n",
    "O modelo linear fica mais simples ao utilizarmos essa biblioteca:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/qb/ft804ytj60d37r560fhfyxhw0000gn/T/tmpg1sh5rgh\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_tf_random_seed': 1, '_keep_checkpoint_every_n_hours': 10000, '_keep_checkpoint_max': 5, '_model_dir': '/var/folders/qb/ft804ytj60d37r560fhfyxhw0000gn/T/tmpg1sh5rgh', '_session_config': None, '_save_summary_steps': 100}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/qb/ft804ytj60d37r560fhfyxhw0000gn/T/tmpg1sh5rgh/model.ckpt.\n",
      "INFO:tensorflow:loss = 23.0, step = 1\n",
      "INFO:tensorflow:global_step/sec: 1246.46\n",
      "INFO:tensorflow:loss = 0.174449, step = 101 (0.081 sec)\n",
      "INFO:tensorflow:global_step/sec: 1400.21\n",
      "INFO:tensorflow:loss = 0.031354, step = 201 (0.071 sec)\n",
      "INFO:tensorflow:global_step/sec: 1446.72\n",
      "INFO:tensorflow:loss = 0.0257966, step = 301 (0.069 sec)\n",
      "INFO:tensorflow:global_step/sec: 1440.47\n",
      "INFO:tensorflow:loss = 0.00163111, step = 401 (0.069 sec)\n",
      "INFO:tensorflow:global_step/sec: 1460.3\n",
      "INFO:tensorflow:loss = 0.00229814, step = 501 (0.068 sec)\n",
      "INFO:tensorflow:global_step/sec: 1478.02\n",
      "INFO:tensorflow:loss = 0.000237329, step = 601 (0.068 sec)\n",
      "INFO:tensorflow:global_step/sec: 1484.63\n",
      "INFO:tensorflow:loss = 7.30248e-05, step = 701 (0.067 sec)\n",
      "INFO:tensorflow:global_step/sec: 1501.55\n",
      "INFO:tensorflow:loss = 2.93949e-05, step = 801 (0.067 sec)\n",
      "INFO:tensorflow:global_step/sec: 1438.91\n",
      "INFO:tensorflow:loss = 5.23356e-06, step = 901 (0.069 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /var/folders/qb/ft804ytj60d37r560fhfyxhw0000gn/T/tmpg1sh5rgh/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.25676e-06.\n",
      "INFO:tensorflow:Starting evaluation at 2017-09-07-02:25:11\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/qb/ft804ytj60d37r560fhfyxhw0000gn/T/tmpg1sh5rgh/model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-09-07-02:25:11\n",
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 3.57538e-07, global_step = 1000, loss = 1.43015e-06\n",
      "INFO:tensorflow:Starting evaluation at 2017-09-07-02:25:12\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/qb/ft804ytj60d37r560fhfyxhw0000gn/T/tmpg1sh5rgh/model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-09-07-02:25:13\n",
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 0.00257771, global_step = 1000, loss = 0.0103108\n",
      "train metrics: {'loss': 1.4301523e-06, 'global_step': 1000, 'average_loss': 3.5753808e-07}\n",
      "eval metrics: {'loss': 0.010310848, 'global_step': 1000, 'average_loss': 0.0025777121}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "feature_columns = [tf.feature_column.numeric_column('x', shape=[1])]\n",
    "\n",
    "estimator = tf.estimator.LinearRegressor(feature_columns=feature_columns)\n",
    "\n",
    "x_train = np.array([1., 2., 3., 4.])\n",
    "y_train = np.array([0., -1., -2., -3.])\n",
    "x_eval = np.array([2., 5., 8., 1.])\n",
    "y_eval = np.array([-1.01, -4.1, -7, 0])\n",
    "\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn({'x': x_train}, y_train, batch_size=4, num_epochs=None, shuffle=True)\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn({'x': x_train}, y_train, batch_size=4, num_epochs=1000, shuffle=False)\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn({'x': x_eval}, y_eval, batch_size=4, num_epochs=1000, shuffle=False)\n",
    "\n",
    "estimator.train(input_fn=input_fn, steps=1000)\n",
    "\n",
    "train_metrics = estimator.evaluate(train_input_fn)\n",
    "eval_metrics = estimator.evaluate(eval_input_fn)\n",
    "\n",
    "print('train metrics: %r' % train_metrics)\n",
    "print('eval metrics: %r' % eval_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construindo um modelo customizado usando tf.estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/qb/ft804ytj60d37r560fhfyxhw0000gn/T/tmpw2z_cfsw\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_tf_random_seed': 1, '_keep_checkpoint_every_n_hours': 10000, '_keep_checkpoint_max': 5, '_model_dir': '/var/folders/qb/ft804ytj60d37r560fhfyxhw0000gn/T/tmpw2z_cfsw', '_session_config': None, '_save_summary_steps': 100}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/qb/ft804ytj60d37r560fhfyxhw0000gn/T/tmpw2z_cfsw/model.ckpt.\n",
      "INFO:tensorflow:loss = 5.31238924081, step = 1\n",
      "INFO:tensorflow:global_step/sec: 1548.4\n",
      "INFO:tensorflow:loss = 0.0391108623444, step = 101 (0.067 sec)\n",
      "INFO:tensorflow:global_step/sec: 1597.67\n",
      "INFO:tensorflow:loss = 0.00322069950067, step = 201 (0.062 sec)\n",
      "INFO:tensorflow:global_step/sec: 1577.46\n",
      "INFO:tensorflow:loss = 0.000274839182001, step = 301 (0.064 sec)\n",
      "INFO:tensorflow:global_step/sec: 1605.8\n",
      "INFO:tensorflow:loss = 1.41812130956e-05, step = 401 (0.062 sec)\n",
      "INFO:tensorflow:global_step/sec: 1615.51\n",
      "INFO:tensorflow:loss = 4.83204831153e-06, step = 501 (0.062 sec)\n",
      "INFO:tensorflow:global_step/sec: 1663.07\n",
      "INFO:tensorflow:loss = 4.04928158187e-07, step = 601 (0.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 1591.31\n",
      "INFO:tensorflow:loss = 1.39264696176e-08, step = 701 (0.063 sec)\n",
      "INFO:tensorflow:global_step/sec: 1513.57\n",
      "INFO:tensorflow:loss = 1.37896800285e-09, step = 801 (0.065 sec)\n",
      "INFO:tensorflow:global_step/sec: 1390.49\n",
      "INFO:tensorflow:loss = 1.42900288603e-10, step = 901 (0.072 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /var/folders/qb/ft804ytj60d37r560fhfyxhw0000gn/T/tmpw2z_cfsw/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.287884729e-11.\n",
      "INFO:tensorflow:Starting evaluation at 2017-09-07-02:32:16\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/qb/ft804ytj60d37r560fhfyxhw0000gn/T/tmpw2z_cfsw/model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-09-07-02:32:16\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 1.47342e-11\n",
      "INFO:tensorflow:Starting evaluation at 2017-09-07-02:32:17\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/qb/ft804ytj60d37r560fhfyxhw0000gn/T/tmpw2z_cfsw/model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-09-07-02:32:18\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 0.0101009\n",
      "train metrics: {'loss': 1.473416e-11, 'global_step': 1000}\n",
      "eval metrics: {'loss': 0.010100947, 'global_step': 1000}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Declare list of features, we only have one real-valued feature\n",
    "def model_fn(features, labels, mode):\n",
    "  # Build a linear model and predict values\n",
    "  W = tf.get_variable(\"W\", [1], dtype=tf.float64)\n",
    "  b = tf.get_variable(\"b\", [1], dtype=tf.float64)\n",
    "  y = W * features['x'] + b\n",
    "  # Loss sub-graph\n",
    "  loss = tf.reduce_sum(tf.square(y - labels))\n",
    "  # Training sub-graph\n",
    "  global_step = tf.train.get_global_step()\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "  train = tf.group(optimizer.minimize(loss),\n",
    "                   tf.assign_add(global_step, 1))\n",
    "  # EstimatorSpec connects subgraphs we built to the\n",
    "  # appropriate functionality.\n",
    "  return tf.estimator.EstimatorSpec(\n",
    "      mode=mode,\n",
    "      predictions=y,\n",
    "      loss=loss,\n",
    "      train_op=train)\n",
    "\n",
    "estimator = tf.estimator.Estimator(model_fn=model_fn)\n",
    "# define our data sets\n",
    "x_train = np.array([1., 2., 3., 4.])\n",
    "y_train = np.array([0., -1., -2., -3.])\n",
    "x_eval = np.array([2., 5., 8., 1.])\n",
    "y_eval = np.array([-1.01, -4.1, -7, 0.])\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_train}, y_train, batch_size=4, num_epochs=None, shuffle=True)\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_train}, y_train, batch_size=4, num_epochs=1000, shuffle=False)\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_eval}, y_eval, batch_size=4, num_epochs=1000, shuffle=False)\n",
    "\n",
    "# train\n",
    "estimator.train(input_fn=input_fn, steps=1000)\n",
    "# Here we evaluate how well our model did.\n",
    "train_metrics = estimator.evaluate(input_fn=train_input_fn)\n",
    "eval_metrics = estimator.evaluate(input_fn=eval_input_fn)\n",
    "print(\"train metrics: %r\"% train_metrics)\n",
    "print(\"eval metrics: %r\"% eval_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
